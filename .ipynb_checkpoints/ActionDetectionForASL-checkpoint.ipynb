{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd3405f-41eb-404b-95b7-4aad4c44134c",
   "metadata": {},
   "source": [
    "## 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c8e0b9-3eb6-4e82-8ad3-f084e2d72943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow opencv-python mediapipe sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc1080b-9fe8-4ecb-b766-96a9efc5007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "import mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a58b4-e23a-4530-85ba-7757d37f3e64",
   "metadata": {},
   "source": [
    "## 2. Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a92cac50-cfa1-460a-a831-09734ad838ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mediapipe.solutions.holistic # Holistic model # detects points\n",
    "mp_drawing = mediapipe.solutions.drawing_utils # Drawing utilities # draws out detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5816da8-b457-416b-87cc-56c8034ca128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # converts color space from BGR to RGB which saves some memory\n",
    "    image.flags.writeable = False                  # marks image as unwriteable\n",
    "    results = model.process(image)                 # Makes prediction\n",
    "    image.flags.writeable = True                   # converts back\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # converts back\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dee251e-e1ca-4dec-a213-0ef3479a2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f665fd59-8dcc-4372-a0ce-5457d891cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                                 mp_drawing.DrawingSpec(color=(68,64,71), thickness=1, circle_radius=1), # joint spec\n",
    "                                 mp_drawing.DrawingSpec(color=(119,155,0), thickness=1, circle_radius=1) # line spec \n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), # joint spec\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2) # line spec\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), # joint spec\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2) # line spec\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), # joint spec\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) # line spec\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc2f4fe-bc9d-4d7e-b391-32cc4527e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0) # access webcam\n",
    "\n",
    "# # Set mediapipe model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     while cap.isOpened(): # while accessing webcam\n",
    "#         # read feed (the current frame)\n",
    "#         ret, frame = cap.read() \n",
    "        \n",
    "#         # Make detections\n",
    "#         image, results = mediapipe_detection(frame, holistic) # holistic: model\n",
    "\n",
    "#         # Draw landmarks\n",
    "#         draw_styled_landmarks(image, results)\n",
    "        \n",
    "#         # show to screen (frame name, actual frame)\n",
    "#         cv2.imshow('OpenCV Feed', image) \n",
    "        \n",
    "#         # condition to close gracefully WHEN:\n",
    "#         #     waited for 0.01 sec for a keypress & keypress is 'q', OR\n",
    "#         #     the [X] button on the window is clicked\n",
    "#         if (cv2.waitKey(10) & 0xFF == ord('q')) or (cv2.getWindowProperty('OpenCV Feed', cv2.WND_PROP_VISIBLE) < 1): \n",
    "#             break\n",
    "        \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61aba0d-5810-4045-83db-ebbe2a3340c0",
   "metadata": {},
   "source": [
    "## 3. Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5a0cd2-4417-4760-b627-f60f2a7f275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose = []\n",
    "# for res in results.pose_landmarks.landmark:\n",
    "#     test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "#     pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90280fe8-51d4-48e3-b25d-dfa5d7eaebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    leftHand = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rightHand = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, leftHand, rightHand])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b18452-6a8c-4cf3-a9b5-e61403e36815",
   "metadata": {},
   "source": [
    "## 4. Setup Folders for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6faf134-d9c0-4c10-ac26-42c600f655be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "\n",
    "# Action that we try to detect\n",
    "# actions = np.array(['hello', 'thanks', 'iloveyou', 'I', 'you', 'deaf', 'hearing', 'what_question', 'what_relative_clause'])\n",
    "actions = np.array(['deaf', 'hearing', 'thanks'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2017db4-a6e2-4e9b-821b-58e9a8e91f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for each sign:\n",
    "# hello\n",
    "## 0\n",
    "## 1\n",
    "## ...\n",
    "## 29\n",
    "# thanks ...\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d316968-6f86-48d8-ae7e-ea4fee036af2",
   "metadata": {},
   "source": [
    "## 5. Collect Keypoint Values for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3fdee2-644b-4542-9024-9f3639e279e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0) # access webcam\n",
    "\n",
    "# # Set mediapipe model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     breakout = False\n",
    "#     # Loop through actions\n",
    "#     for action in actions:\n",
    "#         if breakout:\n",
    "#             break\n",
    "#         # Loop through sequences aka videos\n",
    "#         for sequence in range(no_sequences):\n",
    "#             if breakout:\n",
    "#                 break\n",
    "#             # Loop through video length aka sequence length\n",
    "#             for frame_num in range(sequence_length):\n",
    "            \n",
    "#                 # read feed (the current frame)\n",
    "#                 ret, frame = cap.read() \n",
    "                \n",
    "#                 # Make detections\n",
    "#                 image, results = mediapipe_detection(frame, holistic) # holistic: model\n",
    "        \n",
    "#                 # Draw landmarks\n",
    "#                 draw_styled_landmarks(image, results)\n",
    "    \n",
    "#                 # Apply wait logic\n",
    "#                 if frame_num == 0:\n",
    "#                     cv2.putText(image, 'STARTING COLLECTION', (120, 200),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "#                     cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "#                     cv2.waitKey(500)\n",
    "#                 else:\n",
    "#                     cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12),\n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "#                 # Export keypoints\n",
    "#                 keypoints = extract_keypoints(results)\n",
    "#                 npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "#                 np.save(npy_path, keypoints)\n",
    "                                \n",
    "#                 # show to screen (frame name, actual frame)\n",
    "#                 cv2.imshow('OpenCV Feed', image) \n",
    "                \n",
    "#                 # condition to close gracefully WHEN:\n",
    "#                 #     waited for 0.01 sec for a keypress & keypress is 'q', OR\n",
    "#                 #     the [X] button on the window is clicked\n",
    "#                 if (cv2.waitKey(10) & 0xFF == ord('q')) or (cv2.getWindowProperty('OpenCV Feed', cv2.WND_PROP_VISIBLE) < 1): \n",
    "#                     breakout = True\n",
    "#                     break\n",
    "            \n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f87060-dde5-44d3-9d1d-686fbca76e74",
   "metadata": {},
   "source": [
    "## 6. Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cb7d270-b0c4-4d19-bd69-ad1223abfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5db4abac-72a5-4fc7-934d-f554af40d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89eeb88e-51fe-4e06-9817-54868b48a68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deaf': 0, 'hearing': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b8a0a9-aed2-41d7-bc20-fb8550ac30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "447e2fd2-a996-45ff-9e11-183e3d2c5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63eee9af-2a65-4f72-9c53-de0550299b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7afae1-2742-46fa-8982-adaa9e2a0f5a",
   "metadata": {},
   "source": [
    "## 7. Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70c46800-5533-4cc5-ae6b-b5449fe2d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ae91b3-9f3c-45d6-ac00-5097cfff2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir) # web app to monitor training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e24efc2-df63-4b8a-bd76-d2632ee9c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662))) # 30 frames, 1662 keypoints\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b94a8e7f-66cb-4670-87c7-af1754bb1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e45c20-d3d3-407d-84a9-8d2e78e44a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "2/2 [==============================] - 17s 231ms/step - loss: 0.7092 - categorical_accuracy: 0.5088\n",
      "Epoch 2/90\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.1293 - categorical_accuracy: 0.4035\n",
      "Epoch 3/90\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 1.9129 - categorical_accuracy: 0.5088\n",
      "Epoch 4/90\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.7513 - categorical_accuracy: 0.5088\n",
      "Epoch 5/90\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.7010 - categorical_accuracy: 0.4912\n",
      "Epoch 6/90\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.8679 - categorical_accuracy: 0.4035\n",
      "Epoch 7/90\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.6989 - categorical_accuracy: 0.4912\n",
      "Epoch 8/90\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.6979 - categorical_accuracy: 0.4912\n",
      "Epoch 9/90\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.7053 - categorical_accuracy: 0.4912\n",
      "Epoch 10/90\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.6789 - categorical_accuracy: 0.4912\n",
      "Epoch 11/90\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.6766 - categorical_accuracy: 0.7368\n",
      "Epoch 12/90\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6544 - categorical_accuracy: 0.7018\n",
      "Epoch 13/90\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.7166 - categorical_accuracy: 0.4386\n",
      "Epoch 14/90\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.7106 - categorical_accuracy: 0.5088\n",
      "Epoch 15/90\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.7850 - categorical_accuracy: 0.4912\n",
      "Epoch 16/90\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.6915 - categorical_accuracy: 0.5263\n",
      "Epoch 17/90\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.6979 - categorical_accuracy: 0.5088\n",
      "Epoch 18/90\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.6939 - categorical_accuracy: 0.5088\n",
      "Epoch 19/90\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.6935 - categorical_accuracy: 0.5088\n",
      "Epoch 20/90\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.6931 - categorical_accuracy: 0.5263\n",
      "Epoch 21/90\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.6931 - categorical_accuracy: 0.5088\n",
      "Epoch 22/90\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.6929 - categorical_accuracy: 0.5088\n",
      "Epoch 23/90\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.6927 - categorical_accuracy: 0.5088\n",
      "Epoch 24/90\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.6923 - categorical_accuracy: 0.5088\n",
      "Epoch 25/90\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.6923 - categorical_accuracy: 0.6842\n",
      "Epoch 26/90\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.6932 - categorical_accuracy: 0.6316\n",
      "Epoch 27/90\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.6921 - categorical_accuracy: 0.4912\n",
      "Epoch 28/90\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.6918 - categorical_accuracy: 0.4912\n",
      "Epoch 29/90\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.6912 - categorical_accuracy: 0.6316\n",
      "Epoch 30/90\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.6907 - categorical_accuracy: 0.7193\n",
      "Epoch 31/90\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.6901 - categorical_accuracy: 0.7193\n",
      "Epoch 32/90\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.6929 - categorical_accuracy: 0.5614\n",
      "Epoch 33/90\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.6910 - categorical_accuracy: 0.4912\n",
      "Epoch 34/90\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6871 - categorical_accuracy: 0.6667\n",
      "Epoch 35/90\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.6866 - categorical_accuracy: 0.5088\n",
      "Epoch 36/90\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.6866 - categorical_accuracy: 0.5614\n",
      "Epoch 37/90\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.6772 - categorical_accuracy: 0.8947\n",
      "Epoch 38/90\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.6702 - categorical_accuracy: 0.6667\n",
      "Epoch 39/90\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.6649 - categorical_accuracy: 0.5965\n",
      "Epoch 40/90\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.6511 - categorical_accuracy: 0.5088\n",
      "Epoch 41/90\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 4.2913 - categorical_accuracy: 0.5088\n",
      "Epoch 42/90\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 1.1240 - categorical_accuracy: 0.5614\n",
      "Epoch 43/90\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.6285 - categorical_accuracy: 0.6667\n",
      "Epoch 44/90\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 6.4473 - categorical_accuracy: 0.3158\n",
      "Epoch 45/90\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 4.4708 - categorical_accuracy: 0.3860\n",
      "Epoch 46/90\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 12.9377 - categorical_accuracy: 0.5263\n",
      "Epoch 47/90\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 22.2808 - categorical_accuracy: 0.5439\n",
      "Epoch 48/90\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 11.8175 - categorical_accuracy: 0.5614\n",
      "Epoch 49/90\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 11.5962 - categorical_accuracy: 0.6140\n",
      "Epoch 50/90\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 19.1829 - categorical_accuracy: 0.5088\n",
      "Epoch 51/90\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 2.6085 - categorical_accuracy: 0.3860\n",
      "Epoch 52/90\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 3.8415 - categorical_accuracy: 0.4912\n",
      "Epoch 53/90\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 1.0250 - categorical_accuracy: 0.5088\n",
      "Epoch 54/90\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.9109 - categorical_accuracy: 0.3509\n",
      "Epoch 55/90\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.9637 - categorical_accuracy: 0.4912\n",
      "Epoch 56/90\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 1.7693 - categorical_accuracy: 0.5088\n",
      "Epoch 57/90\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.9637 - categorical_accuracy: 0.4211\n",
      "Epoch 58/90\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 1.4724 - categorical_accuracy: 0.4561\n",
      "Epoch 59/90\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 1.0209 - categorical_accuracy: 0.4912\n",
      "Epoch 60/90\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 1.8381 - categorical_accuracy: 0.4386\n",
      "Epoch 61/90\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 2.6789 - categorical_accuracy: 0.4912\n",
      "Epoch 62/90\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.8029 - categorical_accuracy: 0.6140\n",
      "Epoch 63/90\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 6.0782 - categorical_accuracy: 0.4386\n",
      "Epoch 64/90\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 8.9250 - categorical_accuracy: 0.4912\n",
      "Epoch 65/90\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 8.5466 - categorical_accuracy: 0.5263\n",
      "Epoch 66/90\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 7.2434 - categorical_accuracy: 0.6316\n",
      "Epoch 67/90\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 13.4864 - categorical_accuracy: 0.5263\n",
      "Epoch 68/90\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 11.5939 - categorical_accuracy: 0.5088\n",
      "Epoch 69/90\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 13.4574 - categorical_accuracy: 0.4912\n",
      "Epoch 70/90\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 13.2784 - categorical_accuracy: 0.4912\n",
      "Epoch 71/90\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 4.9084 - categorical_accuracy: 0.6316\n",
      "Epoch 72/90\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 9.1225 - categorical_accuracy: 0.5088\n",
      "Epoch 73/90\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 3.7552 - categorical_accuracy: 0.4912\n",
      "Epoch 74/90\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 3.9068 - categorical_accuracy: 0.4912\n",
      "Epoch 75/90\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 3.6298 - categorical_accuracy: 0.4386\n",
      "Epoch 76/90\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 1.7867 - categorical_accuracy: 0.5965\n",
      "Epoch 77/90\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 1.7529 - categorical_accuracy: 0.5088\n",
      "Epoch 78/90\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 7.1284 - categorical_accuracy: 0.4211\n",
      "Epoch 79/90\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 3.0826 - categorical_accuracy: 0.5088\n",
      "Epoch 80/90\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 10.8174 - categorical_accuracy: 0.5088\n",
      "Epoch 81/90\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 11.4289 - categorical_accuracy: 0.4912\n",
      "Epoch 82/90\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 15.3507 - categorical_accuracy: 0.4912\n",
      "Epoch 83/90\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 8.9083 - categorical_accuracy: 0.5965\n",
      "Epoch 84/90\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 7.8547 - categorical_accuracy: 0.4737\n",
      "Epoch 85/90\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 15.1028 - categorical_accuracy: 0.5439\n",
      "Epoch 86/90\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 27.6018 - categorical_accuracy: 0.5088\n",
      "Epoch 87/90\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 49.6950 - categorical_accuracy: 0.5088\n",
      "Epoch 88/90\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 20.6471 - categorical_accuracy: 0.5088\n",
      "Epoch 89/90\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 17.8381 - categorical_accuracy: 0.4737\n",
      "Epoch 90/90\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 23.9293 - categorical_accuracy: 0.4386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20a64413bd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=90, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a101c2c8-5f29-4e8d-859d-23c85f92c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596642 (2.28 MB)\n",
      "Trainable params: 596642 (2.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037d296-40a5-4c20-90cb-ea26f528d046",
   "metadata": {},
   "source": [
    "## 8.Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "793f10db-01c4-4564-b54a-00cd63b843fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d43179dd-8b72-4233-b213-5e33aabf949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hearing'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0ea4858-5ce0-4143-bd33-bcc685499e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hearing'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b32426f4-5c8b-4f47-b0bd-7af1214c3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bb498-0615-45ba-8ce9-34d019b0ecb8",
   "metadata": {},
   "source": [
    "## 9. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44a73882-889f-45c3-9a95-63002fa559a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('action.keras') # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e76d6f7c-533a-4c6d-ab5a-9de61ac5cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('action.keras') # reload model after initializing and compiling (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad27e6b-597f-4e0e-9638-7d226162bcc8",
   "metadata": {},
   "source": [
    "## Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7af7f46d-b34f-4ce7-81df-73d9f2cce837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0032260c-ceb5-4aad-acc0-b0553cd7da6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77b12b9e-9580-4b8e-b749-a578ccf550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c14bfe-a480-4c5e-9861-80a9efeb275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[0, 1],\n",
       "        [0, 2]]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26f23cb4-20d8-4f75-afbe-15775fe4959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb602c-3b2b-49bd-b7fd-0ddc800fa6b2",
   "metadata": {},
   "source": [
    "## 11. Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7e71599-59fe-4936-9ee2-7debfe723aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "deaf\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "hearing\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hearing\n"
     ]
    }
   ],
   "source": [
    "# 1. Detection Variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "\n",
    "cap = cv2.VideoCapture(0) # access webcam\n",
    "\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened(): # while accessing webcam\n",
    "        # read feed (the current frame)\n",
    "        # timer = 0\n",
    "        ret, frame = cap.read() \n",
    "        \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic) # holistic: model\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "\n",
    "        res = []\n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "        \n",
    "        # visualization logic\n",
    "        if (len(res) > 0):\n",
    "            if res[np.argmax(res)] > threshold:\n",
    "                if len(sentence) > 0:\n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                sentence.append(actions[np.argmax(res)])\n",
    "                    # timer += 1\n",
    "    \n",
    "            if len(sentence) > 5:\n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (640,40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # show to screen (frame name, actual frame)\n",
    "        cv2.imshow('OpenCV Feed', image) \n",
    "        \n",
    "        # condition to close gracefully WHEN:\n",
    "        #     waited for 0.01 sec for a keypress & keypress is 'q', OR\n",
    "        #     the [X] button on the window is clicked\n",
    "        if (cv2.waitKey(10) & 0xFF == ord('q')) or (cv2.getWindowProperty('OpenCV Feed', cv2.WND_PROP_VISIBLE) < 1): \n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a52c3e4-078a-4cc9-8457-aa8868952690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;33m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Generates output predictions for the input samples.\n",
       "\n",
       "        Computation is done in batches. This method is designed for batch\n",
       "        processing of large numbers of inputs. It is not intended for use inside\n",
       "        of loops that iterate over your data and process small numbers of inputs\n",
       "        at a time.\n",
       "\n",
       "        For small numbers of inputs that fit in one batch,\n",
       "        directly use `__call__()` for faster execution, e.g.,\n",
       "        `model(x)`, or `model(x, training=False)` if you have layers such as\n",
       "        `tf.keras.layers.BatchNormalization` that behave differently during\n",
       "        inference. You may pair the individual model call with a `tf.function`\n",
       "        for additional performance inside your inner loop.\n",
       "        If you need access to numpy array values instead of tensors after your\n",
       "        model call, you can use `tensor.numpy()` to get the numpy array value of\n",
       "        an eager tensor.\n",
       "\n",
       "        Also, note the fact that test loss is not affected by\n",
       "        regularization layers like noise and dropout.\n",
       "\n",
       "        Note: See [this FAQ entry](\n",
       "        https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
       "        for more details about the difference between `Model` methods\n",
       "        `predict()` and `__call__()`.\n",
       "\n",
       "        Args:\n",
       "            x: Input samples. It could be:\n",
       "              - A Numpy array (or array-like), or a list of arrays\n",
       "                (in case the model has multiple inputs).\n",
       "              - A TensorFlow tensor, or a list of tensors\n",
       "                (in case the model has multiple inputs).\n",
       "              - A `tf.data` dataset.\n",
       "              - A generator or `keras.utils.Sequence` instance.\n",
       "              A more detailed description of unpacking behavior for iterator\n",
       "              types (Dataset, generator, Sequence) is given in the `Unpacking\n",
       "              behavior for iterator-like inputs` section of `Model.fit`.\n",
       "            batch_size: Integer or `None`.\n",
       "                Number of samples per batch.\n",
       "                If unspecified, `batch_size` will default to 32.\n",
       "                Do not specify the `batch_size` if your data is in the\n",
       "                form of dataset, generators, or `keras.utils.Sequence` instances\n",
       "                (since they generate batches).\n",
       "            verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
       "                0 = silent, 1 = progress bar, 2 = single line.\n",
       "                `\"auto\"` becomes 1 for most cases, and to 2 when used with\n",
       "                `ParameterServerStrategy`. Note that the progress bar is not\n",
       "                particularly useful when logged to a file, so `verbose=2` is\n",
       "                recommended when not running interactively (e.g. in a production\n",
       "                environment). Defaults to 'auto'.\n",
       "            steps: Total number of steps (batches of samples)\n",
       "                before declaring the prediction round finished.\n",
       "                Ignored with the default value of `None`. If x is a `tf.data`\n",
       "                dataset and `steps` is None, `predict()` will\n",
       "                run until the input dataset is exhausted.\n",
       "            callbacks: List of `keras.callbacks.Callback` instances.\n",
       "                List of callbacks to apply during prediction.\n",
       "                See [callbacks](\n",
       "                https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
       "            max_queue_size: Integer. Used for generator or\n",
       "                `keras.utils.Sequence` input only. Maximum size for the\n",
       "                generator queue. If unspecified, `max_queue_size` will default\n",
       "                to 10.\n",
       "            workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
       "                only. Maximum number of processes to spin up when using\n",
       "                process-based threading. If unspecified, `workers` will default\n",
       "                to 1.\n",
       "            use_multiprocessing: Boolean. Used for generator or\n",
       "                `keras.utils.Sequence` input only. If `True`, use process-based\n",
       "                threading. If unspecified, `use_multiprocessing` will default to\n",
       "                `False`. Note that because this implementation relies on\n",
       "                multiprocessing, you should not pass non-picklable arguments to\n",
       "                the generator as they can't be passed easily to children\n",
       "                processes.\n",
       "\n",
       "        See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
       "        `Model.fit`. Note that Model.predict uses the same interpretation rules\n",
       "        as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for\n",
       "        all three methods.\n",
       "\n",
       "        Returns:\n",
       "            Numpy array(s) of predictions.\n",
       "\n",
       "        Raises:\n",
       "            RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
       "            ValueError: In case of mismatch between the provided\n",
       "                input data and the model's expectations,\n",
       "                or in case a stateful model receives a number of samples\n",
       "                that is not a multiple of the batch size.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mbase_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# TODO(yashkatariya): Cache model on the coordinator for faster\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# prediction.  If running under PSS, then swap it with OneDeviceStrategy\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# so that execution will run on the coordinator.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moriginal_pss_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_use_with_coordinator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0moriginal_pss_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Cluster coordinator is set by `.fit()` and `.evaluate()` which is not\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# needed in `.predict()` because all the predictions happen on the\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# coordinator/locally.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster_coordinator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster_coordinator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdataset_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mor\u001b[0m \u001b[0m_is_tpu_multi_host\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mdata_option\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoShardPolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_distribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_shard_policy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mdata_option\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"Using Model.predict with MultiWorkerMirroredStrategy \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"or TPUStrategy and AutoShardPolicy.FILE might lead to \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"out-of-order result. Consider setting it to \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;34m\"AutoShardPolicy.DATA.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdata_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallbackList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallbackList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0madd_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0madd_progbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[0mtmp_batch_outputs\u001b[0m  \u001b[1;31m# No error, now safe to assign.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[1;32mlambda\u001b[0m \u001b[0mbatch_output\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[1;32mlambda\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_output\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                    \u001b[0mbatch_output\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                \u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                            \u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mbatch_outputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"Unexpected result of `predict_function` \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"(Empty batch_outputs). Please use \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"`Model.compile(..., run_eagerly=True)`, or \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"`tf.config.run_functions_eagerly(True)` for more \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"information of where went wrong, or file a \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34m\"issue/bug to `tf.keras`.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mall_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mbatch_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpotentially_ragged_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# If originally PSS strategy was used, then replace it back since\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# predict is running under `OneDeviceStrategy` after the swap and once\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# its done we need to replace it back to PSS again.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0moriginal_pss_strategy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_pss_strategy\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\xuyen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages\\keras\\src\\engine\\training.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.predict??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
